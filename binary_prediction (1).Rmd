```{r}
library(quanteda)
library(ggrepel)
library(textclean)
library(tidyverse)
library(glmnet)
library(pROC)
library(knitr)
library(dplyr)
library(dtplyr)
library(data.table)
library(lubridate)
library(xts)
library(PerformanceAnalytics)
library(knitr)
library(kableExtra)
library(dplyr)
library(sentimentr)
library(doc2concrete)
library(textclean)

# install.packages("stringr")
# install.packages("pROC")
library(stringr)
library(pROC)

# undersampling 
library(caret)
library(ROSE)

# r source files 
source("TMEF_dfm.R")
source("vectorFunctions.R") # a new one!

# Classifiers
library(naivebayes)
library(randomForest)
```

# Pre-processing
```{r}
set.seed(2022)
df <- fread("full_dataset-release.csv")
df <- df %>%
  rename(
    tweet = TWEET,
    stock = STOCK,
    one_day_return ="1_DAY_RETURN", 
    seven_day_return = "7_DAY_RETURN",
    date = DATE
  ) %>% 
  mutate(date = as.Date(date, format = "%d/%m/%Y"))
```

#Text Preprocessing for the tweets 

```{r}
# remove NAs
# rows_with_null <- sum(!complete.cases(df))
df <- na.omit(df)

# remove the URLs and replace emojis and html tags
df$tweet <- replace_emoji(df$tweet)
df$tweet <- replace_url(df$tweet)
df$tweet <- replace_html(df$tweet)


# add a new variable that indicates if it's an up or down
df$made_money <- ifelse(df$"one_day_return" < 0, 0, 1)

# Save into RDS file 
# df<-readRDS("df.RDS")
# saveRDS(df,file="df.RDS")

```

# FANG Preprocessing 
```{r}
custom_stop <- c('amazon','Facebook', '@amazon', 'netflix', '@netflix', 'apple', '@apple', 'facebook', '@facebook', 'google', '@google', 'rt','RT','Rt')

faang <- df %>%
  filter(stock %in% c("Facebook", "Apple", "Amazon", "Netflix", "Google"))

non_faang <- df %>%
  filter(!(stock %in% c("Facebook", "Apple", "Amazon", "Netflix", "Google")))

# To print out if any tweets has a substring xxxx 
# filtered_data <- faang[str_detect(faang$tweet, "tear"), ]
# head(filtered_data$tweet)

```

# FAANG models Binary outcome 
```{r}

# Split train test dataset 
train_split <- sample(1:nrow(faang),0.8 * nrow(faang))

# Training data 
train_X <-faang %>%
  slice(train_split)

train_Y <- train_X %>%
  pull(made_money)

# Test Data 
test_X <-faang %>%
  slice(-train_split)

test_Y <-test_X %>%
  pull(made_money)

# Create a DFM of the train dataset 
dfm_train <-TMEF_dfm(train_X$tweet,ngrams=1:2,custom_stop_words = custom_stop) %>%
  convert(to="matrix")

head(test_Y)

# # Read DFM from RDS file instead 
# dfm_train<-readRDS("dfm_faang_train.RDS")
# dfm_test<-readRDS("dfm_faang_test.RDS")

faang_model<-cv.glmnet(x=dfm_train,
                             y=train_Y)

dfm_test <-TMEF_dfm(test_X$tweet,
                               ngrams=1:2,
                               min.prop = 0,
                    custom_stop_words = custom_stop) %>%
  dfm_match(colnames(dfm_train)) %>%
  convert(to="matrix")

# # Save DFM into RDS file
saveRDS(dfm_train,file="dfm_faang_train.RDS")
saveRDS(dfm_test,file="dfm_faang_test.RDS")

test_predict <- predict(faang_model,
                                  newx = dfm_test)[,1]

test_predict_binary=ifelse(test_predict > 0.5,
                           1,
                           0)

table(test_predict_binary,test_Y)


kendall_acc(test_predict_binary,test_Y)

# Accuracy 
round(100*mean(test_predict_binary==test_Y),3)

# extract coefficients
plotCoefs<-faang_model %>%
  coef() %>%
  drop() %>%
  as.data.frame() %>%
  rownames_to_column(var = "ngram") %>%
  rename(score=".") %>%
  filter(score!=0 & ngram!="(Intercept)" & !is.na(score))  

# merge frequencies
plotDat<-plotCoefs %>%
  left_join(data.frame(ngram=colnames(dfm_test),
                       freq=colMeans(dfm_test))) %>%
  mutate_at(vars(score,freq),~round(.,3))

# pipe into ggplot
plotDat %>%
  ggplot(aes(x=score,y=freq,label=ngram,color=score)) +
  scale_color_gradient2(low="navyblue",
                        mid = "grey",
                        high="forestgreen",
                        midpoint = 0)+
  geom_vline(xintercept=0)+
  geom_point() +
  geom_label_repel(max.overlaps = 15)+  
  scale_x_continuous(limits = c(-.2,.1),
                     breaks = seq(-.2,.2,.05)) +
  scale_y_continuous(trans="log2",
                     breaks=c(.01,.05,.1,.2,.5,1,2,5))+
  theme_bw() +
  labs(x="Coefficient in LASSO Model",y="Uses per tweet")+
  theme(legend.position = "none",
        axis.title=element_text(size=20),
        axis.text=element_text(size=16))

```
# View results
```{r}
# Taking a look at example tweets with some of the words we found on the coefficient plot 
plot(test_predict)
combined_df <- cbind(test_X, test_predict, test_Y)
filtered_data <- combined_df[str_detect(combined_df$tweet, "iphone"), ]
head(filtered_data[, c('tweet', 'test_predict','test_Y')])


# Plotting the histogram of values 
ggplot(test_X, aes(x = made_money)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of Outcomes",
       x = "Value",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```


# Benchmark Model with random model 

```{r}

test_X <- test_X %>%
  mutate(text_wdct=str_count(tweet,"[[:alpha:]]+"),
         model_random=sample(test_predict))

kendall_acc(test_Y,test_X$model_random)

```


# Testing FAANG model on non-FAANG companies 
```{r}

dfm_non_faang <-TMEF_dfm(non_faang$tweet,
                               ngrams=1:2,
                               min.prop = 0,
                    custom_stop_words = custom_stop) %>%
  dfm_match(colnames(dfm_train)) %>%
  convert(to="matrix")

test_predict <- predict(faang_model,
                                  newx = dfm_non_faang)[,1]

test_predict_binary=ifelse(test_predict > 0.5,
                           1,
                           0)

# Accuracy 
round(100*mean(test_predict_binary==non_faang$made_money),3)
# Confusion Matrix 
table(test_predict_binary,non_faang$made_money)

```


# Applying Word Vector to FAANG data
```{r}

# Read the word to vec file 
# word vector 
vecSmall<-readRDS("vecSmall.RDS")
load("wfFile.RData")

train_split <- sample(1:nrow(faang),0.8 * nrow(faang))

train_data<-faang%>%
  slice(train_split)

test_data<-faang %>%
  slice(-train_split)

# vdat <- readRDS("faang_vat.RDS")


# # project data onto the word vector
vdat<-vecCheck(faang$tweet,
vecSmall,
wfFile,
PCAtrim=1)

#vdat <- readRDS("faang_vdat.RDS")

vdat_train<-vdat[train_split,]
vdat_test<-vdat[-train_split,]
# Train a vector classifier
lasso_vec<-glmnet::cv.glmnet(x=vdat_train,
                             y=train_data$made_money)

# notice two lines - one is at the minimum, the other is more conservative 
plot(lasso_vec)

# the default chooses the more conservative one, with fewer features
test_all_predict<-predict(lasso_vec,
                          newx = vdat_test)

kendall_acc(test_all_predict,test_data$made_money)

# this is how you use the minimum one - usually it produces better accuracy
test_vec_predict<-predict(lasso_vec,newx = vdat_test,
                          s="lambda.min")


test_predict_binary=ifelse(test_vec_predict>0.5,
                           1,
                           0) 

kendall_acc(test_vec_predict,test_data$made_money)
table(test_predict_binary,test_data$made_money)

round(100*mean(test_predict_binary==test_data$made_money),3)

```

# Combine N-gram with Vector Embedding 
```{r}

dfm_train <-TMEF_dfm(train_X$tweet,ngrams=1:2,custom_stop_words = custom_stop) %>%
  convert(to="matrix")

dfm_test <-TMEF_dfm(test_X$tweet,
                               ngrams=1:2,
                               min.prop = 0,
                    custom_stop_words = custom_stop) %>%
  dfm_match(colnames(dfm_train)) %>%
  convert(to="matrix")


combined_x_train=cbind(vdat_train,dfm_train)
combined_x_test=cbind(vdat_test,dfm_test)

lasso_vec<-glmnet::cv.glmnet(x=combined_x_train,
                             y=train_data$made_money)
# Calculate the prediction 
test_vec_predict<-predict(lasso_vec,newx = combined_x_test,
                          s="lambda.min")


test_predict_binary=ifelse(test_vec_predict>0.5,
                           1,
                           0) 

# Calculate accuracy 
kendall_acc(test_vec_predict,test_data$made_money)
table(test_predict_binary,test_data$made_money)

round(100*mean(test_predict_binary==test_data$made_money),3)

```


# Applying sentiment 
## positive 
```{r}
train_split <- sample(1:nrow(faang),0.8 * nrow(faang))

train_data<-faang%>%
  slice(train_split)

test_data<-faang %>%
  slice(-train_split)

# pull the positive dictionary
positive_dict<-textdata::lexicon_loughran() %>%
  filter(sentiment=="positive") %>%
  pull(word) %>%
  paste(collapse=" ")


pos_dict<-list(uc=textdata::lexicon_loughran() %>%
                 filter(sentiment=="positive") %>%
                 pull(word)) %>%
  dictionary()
head(pos_dict)


test_data$speech_wdct <- test_data$tweet %>%
  tokens() %>%
  tokens_ngrams(n = 1) %>%
  sapply(length)

pos_dict_bow<-test_data$tweet %>%
  tokens() %>%
  dfm() %>%
  dfm_lookup(pos_dict) %>%
  convert(to="matrix") %>%
  apply(2, function(x) x/test_data$speech_wdct)

# pos_sims <- readRDS("pos_sims.rds")

pos_sims<-vecSimCalc(x=test_data$tweet,
y=positive_dict,
vecfile=vecSmall,
wffile = wfFile,
PCAtrim = 1)

#saveRDS(pos_sims, "pos_sims.rds")
```

# Calculate kendall accuracy using positive sentiment 
```{r}

acc_possims<-kendall_acc(test_data$made_money,pos_sims)

acc_possims

acc_posbow<-kendall_acc(test_data$made_money,pos_dict_bow)

acc_posbow
```

# Uncertainty in economics 
```{r}
uncertain_dict<-textdata::lexicon_loughran() %>%
  filter(sentiment=="uncertainty") %>%
  pull(word) %>%
  paste(collapse=" ")

unc_dict<-list(uc=textdata::lexicon_loughran() %>%
                 filter(sentiment=="uncertainty") %>%
                 pull(word)) %>%
  dictionary()

test_data$speech_wdct <- test_data$tweet %>%
  tokens() %>%
  tokens_ngrams(n = 1) %>%
  sapply(length)

uncertain_dict_bow<-test_data$tweet %>%
  tokens() %>%
  dfm() %>%
  dfm_lookup(unc_dict) %>%
  convert(to="matrix") %>%
  apply(2, function(x) x/test_data$speech_wdct)

#pos_sims <- readRDS("pos_sims.rds")

# uncertain_sims<-vecSimCalc(x=test_data$tweet,
#                   y=uncertain_dict,
#                   vecfile=vecSmall,
#                   wffile = wfFile,
#                   PCAtrim = 1)

# saveRDS(uncertain_sims, "uncertain_sims.rds")
uncertain_sims <- readRDS("uncertain_sims.rds")

acc_uncsims<-kendall_acc(test_data$made_money,uncertain_sims)

acc_uncsims

acc_uncbow<-kendall_acc(test_data$made_money,uncertain_dict_bow)

acc_uncbow
```
